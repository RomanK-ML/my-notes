{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38adb225",
   "metadata": {},
   "source": [
    "# Ансамбли алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231f1f4",
   "metadata": {},
   "source": [
    "*Ансамбли алгоритмов* - метод, использующий одновременно несколько обучающих алгоритмов для получения лучшего результата по сравнению с результатами каждого из алгоритмов в отдельности. Этот метод базируется на интуитивном соображении, пришедшем из статистики, согласно которому усреднение результатов наблюдений может дать более устойчивую и надежную оценку, так как ослабляет влияние различных флуктуаций в отдельных измерениях.\n",
    "\n",
    "Большинство приемов в ансамблировании направлено на то, чтобы ансамбль был достаточно разнообразным, тогда ошибки одних алгоритмов будут компенсироваться корректной работой других.\n",
    "\n",
    "Алгоритмы, из которых состоит ансамбль, называются базовыми алгоритмами (base learners), а алгоритм, который комбинирует полученные ответы - мета-алгоритмом (meta-estimator). По сути, при построении ансамбля:\n",
    "\n",
    "1. повышают качество базовых алгоритмов\n",
    "2. повышают разнообразие базовых алгоритмов за счет:\n",
    "    - варьирования обучающей выборки (каждый алгоритм использует различные подвыборки исходной выборки)\n",
    "    - варьирования признаков (каждый алгоритм использует свой рандомный набор признаков)\n",
    "    - варьирования моделей (используются различные модели)\n",
    "    - варьирования в модели (использование различных гиперпараметров в рамках одного алгоритма)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa9f53e",
   "metadata": {},
   "source": [
    "Вообще, существует достаточно много моделей ансамблирования: \n",
    "- голосование/усреднение ответов по независимым алгоритмам (например, *случайный лес*)\n",
    "- кодировка целевых значений и сведение решения задачи к решению нескольких задач (например, каждый класс может кодироваться бинарным кодом, а решение задачи многоклассовой классификации сводиться к решению нескольких задач бинарной классификации - метод *ECOC*)\n",
    "- построение суммы нескольких алгоритмов, где каждый следующий алгоритм строится с учетом ошибок предыдущих (*бустинг*)\n",
    "- построение метапризнаков - ответов базовых алгоритмов на выборке, обучение на них мета-алгоритма (*стекинг*)\n",
    "- однородные ансамбли (например, *нейронные сети*)\n",
    "\n",
    "Рассмотрим одни из самые популярных методов: **бустинг** и **стекинг**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab79f35",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Boosting (Бустинг)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f8e7b4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Главная идея бустинга - последовательное построение базовых алгоритмов, каждый из которых обучается, используя информацию об ошибках, сделанных на предыдущем этапе. Т.е. каждый следующий алгоритм мы строим таким образом, чтобы он исправлял ошибки предыдущих и повышал качество всего ансамбля. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82379dcc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Первый успешный вариант бустинга - **AdaBoost (Adaptive Boosting)**. Основная идея состоит в том, что каждый следующий алгоритм строится, опираясь на объекты, неверно классифицированные предыдущими алгоритмами. Это достигается за счет того, что при построении каждого следующего алгоритма меняются веса объектов: объекты, которые классифицировались неверно, приобретают больший вес, а объекты, которые были определены правильно, - меньший. \n",
    "\n",
    "Подробно разбирать этот алгоритм не имеет смысла, так как его вытеснил градиентный бустинг: оказалось, что AdaBoost является его частной вариацией (что будет показано позднее).\n",
    "\n",
    "Наглядно алгоритм AdaBoost можно представить таким образом: пусть у нас имеются два класса, которые необходимо разделить, а в качестве базовых алгоритмов мы используем деревья решений глубины 1 (т.е. одно дерево может разделить данные только одной прямой линией по горизонтали или вертикали).\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/AdaBoost_1.png) \n",
    "\n",
    "После обучения первого дерева мы получаем такой результат:\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/AdaBoost_2.png)\n",
    "\n",
    "Видим, что веса объектов, на которых ошибся первый базовый алгоритм, увеличились, а веса тех, что были классифицированы правильно, уменьшились (на графике это передается с помощью размера точек).\n",
    "\n",
    "После обучения второго и третьего деревьев соответственно получаем:\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/AdaBoost_3.png)\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/AdaBoost_4.png)\n",
    "\n",
    "После того, как все базовые алгоритмы были обучены, AdaBoost строит финальную модель  путем суммирования произведений веса каждого дерева на его предсказание (т.е. на то, как дерево разделило классы).\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/AdaBoost_5.png)\n",
    "\n",
    "Как видим, в таком варианте полученное разделение соответствует идеальной классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab252bd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**GradientBoosting**. Как понятно из названия, основан на понятии градиента: не вдаваясь в математические подробности, можно сказать, что градиент - это вектор, который направлен в сторону наискорейшего возрастания функции. Соответственно, антиградиент направлен в сторону наискорейшего убывания функции. \n",
    "\n",
    "Допустим, у нас есть выборка, состоящая из признаков *x* и целевых переменных *y*. Идея градиентного бустинга состоит в том, чтобы уменьшить ошибку предсказания классификатора $\\hat{y}$, т.е. уменьшить разность $(y - \\hat{y})$, чтобы она была как можно ближе к нулю. Для этой цели используется т.н. функция потерь, т.е. функция, которая характеризует потери при неправильном принятии решений (одну из них - логистическую функцию потерь - мы упоминали в одном из предыдущих уроков). Если обозначить ее как $L$, то искомую наименьшую разность можно переписать в виде $arg min_{\\hat{y}}\\ L(y, \\hat{y})$, а поиск этой наименьшей разности производится самым простым и часто используемым методом - градиентным спуском.\n",
    "\n",
    "Заметим, что, исходя из использования градиента, функция потерь должна быть дифференцируемой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3425c603",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь разберемся с тем, какие функции потерь мы можем использовать в задаче классификации. Так как оптимизировать сами метки класса довольно затруднительно, обычно используют пороговые значения, когда $\\hat{y} \\in \\{-1, 1\\}$. Наиболее известные функции потерь в классификации:\n",
    "- Logistic loss или логистическая функция потерь: $L(y, \\hat{y}) = log(1 + exp(-y \\hat{y}))$ - самая используемая функция потерь в бинарной классификации;\n",
    "- AdaBoost loss: $L(y, \\hat{y}) = exp(-y \\hat{y})$. Здесь нужно вспомнить про алгоритм AdaBoost: так получилось, что он эквивалентен методу градиентного бустинга с этой функцией потерь. Эта функция имеет более жесткий штраф по отношению к ошибкам классификации и используется реже.\n",
    "\n",
    "В качестве базовых алгоритмов здесь обычно используются решающие деревья. При этом решающие деревья выбираются неглубокими: глубина варьируется от 2 до 7. Этого вполне достаточно, чтобы восстановить сложные закономерности с помощью бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1ef8b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Еще одна эффективная вариация градиентного бустинга на деревьях решений - **XGBoost (eXtreme Gradient Boosting)**. Модель представлена отдельной одноименной библиотекой. По сравнению с классическим градиентным бустингом, в данной реализации больше возможностей для регуляризации базовых решающих деревьев и задачи бустинга в целом. Выделяют три группы параметров:\n",
    "- общие параметры, отвечающие за выбор базового алгоритма и распараллеливание;\n",
    "- параметры базового алгоритма решающих деревьев: скорость обучения (чем ниже, тем больше итераций нужно для обучения модели с хорошим качеством), максимальная глубина дерева, минимальное необходимое число объектов в каждом листе, доля выборки для обучения каждого дерева, доля признаков для каждого дерева, коэффициенты перед L1- и L2-регуляризаторами функции потерь;\n",
    "- параметры задачи обучения: используемая при обучении функция потерь, метрика качества на валидационной выборке, параметр воспрозводимости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8204623",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь перейдем к практике. Библиотека sklearn предоставляет нам готовую реализацию алгоритмов AdaBoost и GradientBoosting, а вот XGBoost придется импортировать из другой библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c56934",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52c988a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Все рассмотренные методы являются композициями алгоритмов. Логично предположить, что их качество будет зависеть от количества базовых алгоритмов, над которыми они строятся. Давайте на примере этих алгоритмов проанализируем, как изменяется качество алгоритма в зависимости от количества деревьев, на которых он построен.\n",
    "\n",
    "Для демонстрации используем уже преобразованные в одном из предыдущих домашних заданий данные задачи из Kaggle - Titanic.\n",
    "\n",
    "Вспомним, как они выглядят."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98d4afca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0         0       3    1  22.0      1      0   7.2500         1\n",
       "1         1       1    0  38.0      1      0  71.2833         2\n",
       "2         1       3    0  26.0      0      0   7.9250         1\n",
       "3         1       1    0  35.0      1      0  53.1000         1\n",
       "4         0       3    1  35.0      0      0   8.0500         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "titanic = pd.read_csv('titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5e6e0f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Сразу отделим целевую переменную Survived. На тренировочный и тестовый датасеты данные разделять не будем - сделаем проверку производительности на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa09c5bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets = titanic.Survived\n",
    "data = titanic.drop(columns='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178cea7e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Зададим количество деревьев в алгоритме: 1, а далее от 10 до 100 с шагом 10. В алгоритме за этот гиперпараметр отвечает n_estimtors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0cf67af",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trees = [1] + list(range(10, 100, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768bd8b7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь последовательно обучим алгоритмы AdaBoost, GradientBoosting и XGBoost и проверим на трехкратной кросс-валидации, как изменяется точность классификаторов в зависимости от количества базовых алгоритмов. Заодно посмотрим на время обучения каждого из алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0285637e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 s, sys: 0 ns, total: 2.1 s\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ada_scoring = []\n",
    "for tree in trees:\n",
    "    ada = AdaBoostClassifier(n_estimators=tree)\n",
    "    score = cross_val_score(ada, data, targets, scoring='roc_auc', cv=3)\n",
    "    ada_scoring.append(score)\n",
    "ada_scoring = np.asmatrix(ada_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fdc6110",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.77164222, 0.78587863, 0.7430975 ],\n",
       "        [0.79997124, 0.85557473, 0.86624005],\n",
       "        [0.80560349, 0.85092513, 0.88447896],\n",
       "        [0.79925223, 0.84766561, 0.88562937],\n",
       "        [0.80236794, 0.84502924, 0.87553926],\n",
       "        [0.80059438, 0.8420094 , 0.87553926],\n",
       "        [0.80040265, 0.84112262, 0.88050043],\n",
       "        [0.80136133, 0.84210526, 0.88203432],\n",
       "        [0.80299108, 0.84385486, 0.87340619],\n",
       "        [0.8038539 , 0.84450197, 0.87824753]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a2afe93",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.31 s, sys: 0 ns, total: 1.31 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gbc_scoring = []\n",
    "for tree in trees:\n",
    "    gbc = GradientBoostingClassifier(n_estimators=tree)\n",
    "    score = cross_val_score(gbc, data, targets, scoring='roc_auc', cv=3)\n",
    "    gbc_scoring.append(score)\n",
    "gbc_scoring = np.asmatrix(gbc_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97a694c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.81430352, 0.84991851, 0.87491612],\n",
       "        [0.81763493, 0.87117726, 0.88677979],\n",
       "        [0.83158374, 0.87364586, 0.88179465],\n",
       "        [0.81708369, 0.8781996 , 0.8825616 ],\n",
       "        [0.81782667, 0.87374173, 0.88186655],\n",
       "        [0.81451922, 0.87098552, 0.88730707],\n",
       "        [0.81413575, 0.86930783, 0.88349631],\n",
       "        [0.80998945, 0.86983511, 0.88126738],\n",
       "        [0.80982169, 0.8715128 , 0.87635414],\n",
       "        [0.81380021, 0.87192024, 0.87496405]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64807aad",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:42:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 3.21 s, sys: 395 ms, total: 3.61 s\n",
      "Wall time: 2.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "xgb_scoring = []\n",
    "for tree in trees:\n",
    "    xgb = XGBClassifier(n_estimators=tree, use_label_encoder=False)\n",
    "    score = cross_val_score(xgb, data, targets, scoring='roc_auc', cv=3)\n",
    "    xgb_scoring.append(score)\n",
    "xgb_scoring = np.asmatrix(xgb_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd1ae5e3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.8108283 , 0.86564088, 0.87714505],\n",
       "        [0.80967788, 0.89497651, 0.86614419],\n",
       "        [0.81658039, 0.88625252, 0.86156648],\n",
       "        [0.8127936 , 0.88191449, 0.8582111 ],\n",
       "        [0.81324897, 0.87800786, 0.85694085],\n",
       "        [0.81125971, 0.87865497, 0.85698878],\n",
       "        [0.81056466, 0.87760042, 0.85646151],\n",
       "        [0.81032499, 0.87386157, 0.86183012],\n",
       "        [0.80816796, 0.8758748 , 0.85881028],\n",
       "        [0.80792829, 0.87395743, 0.85665325]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc270019",
   "metadata": {
    "hidden": true
   },
   "source": [
    "На первый взгляд алгоритмы работают практически идентично. Теперь посмотрим на графике, так ли это. Обратите внимание на то, что алгоритм XGBoost работает в 2 раза быстрее, чем GradienBoosting, и почти в 4 раза быстрее, чем AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c4dcc69",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff5d0fd58b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA95UlEQVR4nO3deXxb1Z338c9PsuR9idcsdshC9j0xhK3UQGEoSyGFNrRMO5D2YWiBblMK7bR9Ci1TKDxTOoUZynTJtGUClCY0pTChQAyEoZDFju1sJCQkXhLHSyzvm3SeP64ky7YcKyGyLOn3fr30ku7V1dXxiXO/Pufce64YY1BKKaWGskW6AEoppcYnDQillFJBaUAopZQKSgNCKaVUUBoQSimlgkqIdAHOpNzcXDNt2rSQtu3o6CA1NTW8BYoyWieDaX0Mp3UyWCzUx/bt2xuNMXnB3oupgJg2bRrbtm0LadvS0lJKSkrCW6Aoo3UymNbHcFong8VCfYjI4ZHe0y4mpZRSQWlAKKWUCkoDQimlVFAaEEoppYLSgFBKKRWUBoRSSqmgNCCUUkoFFVPXQajT0NcNdTugdjsTjx6DukzImweOpEiXTCkVYRoQ8aa9Aar/Bkf+BtXvQF05ePoAmAuw7zEQO+TOhokLYeIiKPA+p+VHsuRKqTGmARHLPB5o2m+FwZG/WcHQfNB6z+6Eycvh/C9D0XlQeA7vvPEKK6elwLFKOFYFh9+Gyj8M7C+tYCAsfMGRczbY9ddIqVgU1v/ZInIl8DPADvzSGPPgkPczgd8DU71lecQY8xvve1nAL4GFgAHWGGPeDmd5o15fF9SVDbQOqt+BrhPWeyk5VhCsuMV6nrwUEhIHfbwrZRLML4H51w2s7GyG+l1WaNRXwbEKePtxf6uDhCTIn+cNDF9wLICkjLH4iZVSYRS2gBARO/A4cDlQA2wVkY3GmN0Bm90B7DbGXCsiecA+EXnKGNOLFSz/Y4y5UUScQEq4yhq1TtJdRM4smHsNTD3PCoScmSBy6t+Rkg3TP2I9fPp7ofE9b2BUWo+9f4Edvx3YJuusgZaGr7WRNfX0yqCUiohwtiDOBQ4YYw4CiMjTwHVAYEAYIF1EBEgDmoF+EckALgZuAfAGRm8Yyzr+eTzWQbn6b3DknSHdRYkwedlAd1HRSkjNCV9ZEpze8YmFsOQma50x0HbU6po6VuENjyorOPDe9zwx0/qMv5tqoQ6IKzWOiTEmPDsWuRG40hjzRe/y54CVxpg7A7ZJBzZijY+mA6uNMX8RkaXAk1hhsgTYDnzVGNMR5HtuA24DKCgoWPH000+HVL729nbS0tJO/wcMM5u7h/S2A2S69pDRupdM114c/W0A9DoyaM2YhytzLq7MebSln42xOT70d4ajTmzublI7DpPWfoi09g9Iaz9IWvth7J5uAAw2OlMKaU+bRnvadNrTptOVPJleZxYee+Ioew+v8f47EglaJ4PFQn1ccskl240xxcHeC2cLIlhfwtA0+jugHLgUmAn8VUTe9JZrOXCXMeYdEfkZcC/wvWE7NOZJrDChuLjYhDr17ribpvdk3UW5s2HR9f7uImfOTHJFyD3DRRizOvF44MQhOFaJ1FeReqyS1GNVFBx/Y/B2zjRIzYXUfOsMqtS8gWf/63xrm6TMM959Ne5+R8YBrZPBYr0+whkQNUBRwHIhUDdkm1uBB43VjDkgIoewWhNHgBpjzDve7Z7DCojY0t4Ar/0QPngzct1FkWCzWWMiOTNhwfUD6zubra6pliPQ0WDVT8dxaD8OzYes4OxoZPjfGVj1lpoHaXne0Ah4PTRUkrOtMiilTiqcAbEVmCUi04Fa4Cbgs0O2OQJcBrwpIgXAHOCgMaZRRKpFZI4xZp93m93EkqMV8PRnrQPhzMtOenZR3EjJhukXn3wbjxs6m6zQ6GjwBslxb5D4lo9ZA+cdDQOtsEBiH2iZpOYGaZ3kQ1oeSV314KoBW4L1GZsdxGY9D12ng+8qBoUtIIwx/SJyJ7AJ6zTXXxtjdonI7d73nwB+CKwVkUqsLql7jDGN3l3cBTzlPYPpIFZrIzbs2gDPfxmSJ8CaTVYoqNDY7NaBPJSL9oyxTvPtaBxoifgDJSBcmt+3wqW/a9DHzwN4J+iehxPbkNDwPge+DrYu6PsJA0EkdusPhowpkFkIWUWQWWS9Ts3XlpAKq7BeB2GMeRF4cci6JwJe1wFXjPDZciDowEnU8nig9Mfwxk+gaCW9N/6ass5a0pt2MyVtCpmJmZEuYWwRsVolKdmQN3v07XvaA1oix9lb/i5z58wCT7/VcjEe77M7tHWefu963/ueIOuGvPY9u/sGXvd1waE3oKd1cHntzoDgmGo9ZxZ6A6QIMqeAIzk8davigl4CO1Z62mD9P8K+v7Bv8So2TJ7FCy/dhKvH5d8k3ZHOlPQpTEkbeBSmFzIlbQqT0yaTnKD/2cMqMc16ZM8A4Fh9OnOXl0S2TIG6XVaXV0s1uKqt177n9zdbpxkPHZ9JzQsIjoAQ8bVEUnK0e0yNSANiLDQfonXdTbzUU8f6eSvY3bYdx/4KLpt6GVdNvwq3cVPbXktNWw217bUcch3irdq36HZ3D9pNTlKOP0AK06zg8C1PTJ2I4wyc6qrGsaRM61GwIPj77j5orRscHi3e1w3vwYFXoa9z8GcSkgMCZGhLpBAyCq3rXlRc0oAII4/xsLXsl2x49195JTWBnrQsZidP4N7FX+Dq6VeTlZQ14meNMTR1N/lDw/9oq6WioYKXP3gZt3H7t7eLnYKUgkEtkML0Qn+Q5CbnIvqXYmyzO2DCWdYjGN+YTMsRb4D4WiDeEHlvk9XFNohYc3B5Wx0zWg0k7wvoyiq0xtL0dysmaUCEwbGOY/zpwJ94ftdvqelrJT3JwfXTPs6qRf/A/Oz5IR2oRYTc5Fxyk3NZmr902Pv9nn6OdRzzB0dgkGyp3UJjV+Og7RPtiUxOmzwQHmmFg8JExz/iQOCYzEgnRvR1Q2ttQCskoEvr6E4KT1RD9fODP+NIDei2GjoOUggZk63wUlFHA+IM6XX3UlpdyvoD63m77m08xsO5Xd3ckXY2H1v1O5JSz+xlbQm2BKuFkF4Y9P3u/m7q2uuoaa/xtzx8AbKzYSdtvW2Dtk93pDPRNpHKskqW5S9jSd4S0p3pZ7TMKgo4kgauUQnijc2vUXLOwoEAaRkyFlJXDp2NQz4lkD5pSIgMCZMwXOioPjwNiA9p/4n9rN+/nhcOvkBLTwsFyXl80Z3C9bX7KLrgG1DynYicipiUkMSMrBnMyJoR9P3W3tZBoVHdVs3/HvpfflX5K9zGjSDMmjCLZfnLWJq/lOX5y5mUOkm7qeKd2AZOM56yIvg2vZ2DWyGBIVK7A/b8GdxDplZzpg8ZQA8MkSIrYHRa+TGnNX4a2nrbeOnQS2zYv4GqpioSbAlcUnQJn8xeyvmvPIS9swmu/yUs/GSkizqiDGcGGTkZzMuZ519X2l3KuReeS0VjBWXHyyg/Xs4LB1/gmX3PAJCfks+y/GX+x+wJs0mw6a+QGsKZArmzrEcwHo811hHY8gjsyqrdDl3Ngz8jNkifPBAiqXnW2EdylvWc5H32rUvKis1AMQZ626G71Tqrrcf7bDww5+Nn/OtisAbDwxjDtvptbNi/gb8e/ivd7m7Ozjqbb53zLa6ecTXZBzbD83dYpw1+YRNMWhLpIp+WFEcK5006j/MmnQeA2+Nmf8t+yo6XUVZfRllDGZs+2GRtm5DCorxFLM9fztL8pSzJW0KqIzWSxVfRwGaD9InWo3CES516O4YHiC9EarZa07IM6SYdxpnuDYzMgfDwB0nWyOucaeHr7urvHTio+x7+5dbhyz2t0N0y+D3jGb7f1Dy4+8AZL64GxCjqO+rZ+P5GNhzYQHVbNWmONK6deS2rzl7FwtyFiDGw+QF48xFrqozVv4upW3PabXbmZs9lbvZcPjP3MwAcbT9qBcbxMsobyvlFxS/wGA82sTFnwhyW5i/1tzImpk6M8E+gopIzFfLmWI+RuPusg2bXCehqsZ67WwYvB647vndgXbApWHxsCcNDY4RgyWmshJ31gw/kJzvgD7lafziBxAzvKc3e54xCyPe+HvpeYoa3bFmh1+0p0IAIos/dx+s1r7N+/3reqnsLj/FQXFDM7Utu5/KzLh+4YK27FTb8I+x7EZb/A1z1SFycMz4pbRKT0iZx1YyrAGjvbaeioYKyBis0nj/wPOv2rrO2TZ3kD4zl+cs5O+ts7DZ7JIuvYoXd4Z1T6xRPADHGuh4k1GBpPw4N+7wB4Bq0q0UAVQErEpKGH8QzC4cc1DODHOS9y870cTV9igZEgPdb3vcPODd3N5OXnMeahWtYdfYqpmZMHbxx80FY9xlo3G8FwzlfjNuzMNKcaVww5QIumHIBYJ2Cu+/EPsqPl7Ojfgfbj23npUMvWds60lict9jfwliUu4gUh94sUI0hEauF4vSennsqPO5BrZbtO7az4oJLBw7wMTbRZtwHRK+719+FVNFQQYIkUFJUwqpZq7hg8gXBB2Hf3wx/uMX6RfvcBpjx0TEv93iWYEtgQc4CFuQs4OZ5N2OMoa6jjh31Oyg/Xk5ZQxn/Xv7vGAx2sTMne45/HGNZ/jLyU2Kni07FGJt94FoSoO1AG+SeHeFChU/cB4Qg/Lzs52QlZvHN4m9yzYxryEke4f4LxsA7v4BN37H6Rm/6b8iePrYFjkIi4r8g79qZ1wLWabY7j+/0j2M8995z/H7P7wHITMwkLzmPnOQc8pLz/BcM+h6+9zKcGXrarVJhFPcB4bA7eOaaZyhIKTj5waa/B/7yDSj7Pcy9BlY9AYl6IdnpynBm8JHCj/CRwo8A0OfpY2/TXsqOl3Gk7QiNXY00djVSdryMhs4Gej3Db0nutDmHhUduivc5KZe8FCtccpJycOiVvEqdsrgPCGD0M23a6uHZz1l3NLv4W1Dy7XE1kBQLHDYHi/IWsShv0bD3jDG097XT0NVAU1cTDZ0NVoB0N9LYaQXJkbYjlB0v40TPiaD7z0rMCtoK8b32hUu6I11bJUp5aUCMpq4Mnr7ZGpT61FpYsCrSJYo7IkK6M510ZzozMoNfGe7T5+mjqavJCpKuBn9LxPdo6Go4aask0Z5otTqSc3C3u/nT5j/hsDlw2B047U4cNgdOm9P/2mG3ln3Poa7378vuxGlzkmBL0GBS444GxMlUPgd/usO6CGXNJpi0ONIlUqNw2BxMTJ04aqvQGENbX5sVHJ2NQYOk1l1LT2sPfZ4++tx99Hp66XX3+pf7Tf8ZL3tgCDnsDhw2B4n2RJITkklxpJCSkEKKI8VaTkgh2ZE8bJ1vu6GfcdqcURNCHuOhz9NHr7uXHnfPsPpPsif5/2hISkiKdHFjlgZEMB43vPZD2PJTmHoBfPq3kJYX6VKpM0hErOlGnBkjtkpKS0spKSkZcR9uj9sKC++BLFiQ9Lp76fX00ufuG7zs+4xv/ZDPBD73uHvo6u+ivbed453H6ezrpKu/i87+TnrcPSH/zDaxWWERECiBITI0UIauS0pIYk/XHswRM6y8Pe6egZ/P+zMOfR1YNyNt43vd7wk9fJ02pz8sMhIzrGdHhv91ujOdDOfA60xnpv91ujNdp4s5Ca2Zobpb4Y9fhP2bYMWt8PGfxMXFb+rU2W127DY7SUTuL9h+T78VFgGh0dnXSWd/p3994Otg25zoPkFtf+3Aur6uk7eOht4yYogEW4K/G83XEkq0Jw5aTnWkkm3P9nfd+bcf8trXggrsknPYHPS4e2jrbaO1t5XW3lbrdY/17Op2Ud1a7X8/8L4pwaQkpAyEicMKGV+gBAZL4Drfa2PMSfcd7TQgAjW9b1381vw+XP3/rIvflBrHEmwJ/gPYmdTn7vMHiS9Uuvq7qCyvZGXxSv9YSqI9cdhB3ibj5wQOYwxd/V0DIeJ9Hilc2vraONp+lPd63/Mvn4wdOznP5pCTnEN2UjbZSdkjvs5OysZpj64/NjUgfA68Cs/dCmKHzz0P0z8S6RKNiT63h9f2HmfjzjpONPawV95ndkEaswvSmZKVHDV91urMctgdZNozh91IqiOpgwW5I9zydBwSEauLzJFyWvOCuT1u2vvag4dLTysV+ytIy0+jqbuJ5q5mDrkO0dTdNGLXX7oznZyknKDhMTRYxsMZdRoQxsDf/h1e/i7kzYPP/DdMmBbpUoXdwYZ2ntlWzR+319LY3kNuWiKefjf/+9Je/zZpiQmcnZ/GnIJ0Zk9Mt54L0shLT4z4L65SY8Fus5OZODwofUobSym5sGTQOmMMnf2dNHc109TdZIVHd7N/ubm7mebuZg62HGRr91ZaelqC7jvBlmCFRVIO2cnZA8HiXfaHiXd9OK710YDoOgFv/QzmXAWrfgGJaZEuUdh09vbzYuUxnt1azbsfNGO3CZfOzWd1cRElc/LY8uYbLFt5Ifvr23ivvp336tvYd6yNV/bU88y2av9+slIczPaGhRUa1mNCanQ1n5UKBxEh1ZFKqiOVooyiUbfv9/TT0tNinZ7tDZCmroEg8S0fbDlIU1dT0NOzMxMz2XLTljP+s2hApGTDF1+xptSNwYvfjDFU1Lh4ems1f95ZR3tPP9NzU7nnyrncsGIK+emDB1gzkx0UT8umeFr2oPWN7T28V9/Ge8faeO94O+8da+NP5XW0dQ8MZualJwYERhqzJ6YzKz+N9CS9ilmpkSTYEvwXcI7GGENHX8eg4Gjqbhp1IP60yxaWvUabrKmjbxNlTnT0sqGslme3VbP3WBtJDhtXL5rM6nOKOGfahFPuIspNSyQ3LZELZg78EhtjONbabbU2jrWxr76N9+rbWPfuEbr6Bn5hp2Ql+wPDFyBn56eR5NBpv5U6FSJCmjONNGfa8Bmmw0ADIoZ4PIa33m/kma3VvLyrnl63hyWFmTywaiHXLplMxhn+S15EmJSZzKTMZD46e+A6EY/HUHOiyx8Yvq6qtw400eu27oZlEzgrJ5VZ+WnMmTjQTTU9NxVnQuy15JSKRhoQMaCupYs/bKvhD9urqTnRRVaKg8+unMrqc4qYNyljzMtjswlTc1KYmpPC5fML/Ov73R4+aOr0B4YvPF7dexy3xzqfPMEmnJ2fxoLJmSyYnMHCKZnMn5xBWqL+qio11vR/XZTq7ffwyp56nt5azZv7GzAGLjo7l29dOZcr5heMy+6bBLuNs/PTODs/jasWTfKv7+5zc7Chg/3H29h7rI09R1t5/b0G/rijBrBuuzE9J5X53sBYMDmDBZMzydZBcaXCSgMiyrxX38YzW6vZUFZLc0cvkzKTuOvSWXxqRSFF2dF5Z7Ykh535kzOYPzmD6wLWH2/tpqrOxa7aVqrqXJQdaeGFiqP+96dkJVuhMTmThVOs8MjXU3CVOmM0IKJAe08/L+ys45lt1ZQdacFhFy6fX8Cni4v4yKw87LbYPCDmZyRxaUYSl84d6KZq6exlV10rVbUu67nOxSt76vHNeJCb5hzUPbVwciZF2XrBn1KnQwNinDLGsOPICZ7ZWs0LFUfp7HUzKz+N7149j1XLppCTFlv3vg1VVoqTC8/O5cKzB86m6ujpZ8/RwNBo5a03DtLvHddIT0qwAmNyJgumWM8z8tJiNlhjXU+/G6fdFnehb4yhsb2X6hOdVDd3UnOii5oTnVQ3dwHw+y+uPOPfqQExzjS297BhRy3PbKvmwPF2Upx2rl08mU+fU8TyqVlx958iFKmJCcOu3ejuc7O/vp2qOpc/OH73t8P09FtnUSU77MydlO7vnlowOZNZBWkkJoy/sZtYZIyho9eNq6uPls5eXJ19tHT10dLZR0uXd9n7uqWzz7udtdzd58GZYKMgI5GJGUkUZCQxMSOJiZneh3ddQUZS1J0R5+rq8x78rQP/4DDoGnT6OEBOqpPC7BRm5qaGpTxhDQgRuRL4GWAHfmmMeXDI+5nA74Gp3rI8Yoz5TcD7dmAbUGuMuSacZY0kt8fwxv4Gnnm3mlf21NPvMSyfmsVDNyzi6sWT9Qye05DksLOoMJNFhQNTJPS7PRxs7KCq1kVVbSu76lw8X1bL7/52GACHXZhdkO7vnupoclPU0E5+eiJpiXpDn2A8HkNbd7//QN7iO+D7DuiBB/wh7/laeME4E2xMSHGQlewkM8XB1OwUFhc6yEpxkpGUQFtPP8dc3RxzdVNVa3Uzdvd5hu0nJ9VpBUhAeEzMSKIg4HVG8tj923b29lNzost/0K9u7vSGgBUGgReeAqQnJlCYncL03FQunp1H0YRkirJTKMpOYUpWMqlhPjaEbe/eg/vjwOVADbBVRDYaY3YHbHYHsNsYc62I5AH7ROQpY4zvWvKvAnuAsT9XcwwYY/j30vf5/d8Oc9TVTXaqk1sumMbqc4qYVaD3uz7TEuw2//UWn1xurfN4DEeaO/3jGdbB5jjPbrPOoHpo6+uA1eLIz0gkPz2RvPRE8tOTvM8Dy/kZiWSnOLFFaddVb7+Hls5emjt7ae7o5URHH82dvZzo8C539nKwppuf7noLV2cvLV3WX/Ynm/E6LTGBzGQHWSnWY+7EDDJTHGT51nkDICvZ4X12kpXiOOWz8IwxtHb1c6y1m2Ot3dS7ujnq8r5utYJkZ3ULTR3Dp6lIctgGWiBDwsP3Oj89kQT76K2R3n4PdS1dgw76A4HQSWP74O9PctgonJBC0YRkVpw1gaLsZIomWAFQNCGFzJTIzkIQzvg5FzhgjDkIICJPA9cBgQFhgHSx4jsNaAb6vdsXAlcDDwDfCGM5I2brByd4eNM+zp+Rw/evmc9l8wqirkkc7Ww2YVpuKtNyU7l6sXXqre8K8Q2v/C+TZszheGsPDW09HG/r4XhbN3uPtfHm/sZhf+0B2G1CbprTCoz0RPIzEslLSyTPe5DxBUpeemJYu7PcHoOrq89/YLcO+L3+A36Tf7mPE97XbT0j3wMiPSmBCSlO7G5DUbaDs7JTvAd4B5kpzoEDfoqDTO9BPjPZgSOEg+qZICJkplghM2fiyH9c9fS7Od7aQ32rFSC+8PAFyfYjJ6h39fgv6BzYvzWbwKTMwV1a7x3oZePxcmq8YXCstXtQYCbYhMlZyRRlJ/OxeQUUZadQOCHZCoXsZPLSxvdZd+EMiClAdcByDTB0FOUxYCNQB6QDq40xvn+ZR4FvedfHpIqaFgD+7TPLyEuPz0Hn8ch3hfj8HDslywpH3K6r1+0Nju5BAXK8tYeG9h6OurrZWeOiqaMn6F/ZWSmOwS2QgPDwtUh83VttPf2D/pJv7uijuaOH5o6+QQd+33PLSf6yT3bYyU51MiHVwYQUJ9NzUpiQ6iQ7xWk9pzqZkOL0b5OV7PT/4WLdZe/cM1HNEZGYYPd30YzEGMOJzj6Ourq8AdLjb5Uca+2murmTdw814+rqQ4CJmU0UTkjm/Bk5FGanDOoGKgix5TFehTMggsXi0F/ZvwPKgUuBmcBfReRN4GLguDFmu4iUnPRLRG4DbgMoKCigtLQ0pMK1t7eHvG24vLKzm+wkYdf2tyNaDp/xUCfjyanURzJwFnBWIpDnfQCQgNtjp7XX4OoxtPQEPPcaXD1dHGvoZG+Ntdw/vBsdYfh/HB+7QLpTSHcKaQ7IdQrTcoV0h4M0p5DuEOvZCWne14l2339NN9DlfXh1W4+eJjiK9TjdOokFNmAyMNkB5HofADjpdTvo6OhgQoYd6PU+WqAdutth/xHYH4lCn0HhDIgaIHCu20KslkKgW4EHjXXfvgMicgiYC1wIfEJErgKSgAwR+b0x5u+Hfokx5kngSYDi4mJzsnsIBxrtfsNj4f5tpRTPSKOkpDii5fAZD3Uynox1ffj60Y+3dXO8rcffOmnt6icrxRHwV73vr33HmA+e6+/IYLFeH+EMiK3ALBGZDtQCNwGfHbLNEeAy4E0RKQDmAAeNMd8Gvg3gbUF8M1g4RLPW7j4ONnawatmUSBdFjROB/eh6koIaD8IWEMaYfhG5E9iEdZrrr40xu0Tkdu/7TwA/BNaKSCVWS/oeY0xjuMo0nuyqbQUYdBqmUkqNJ2E9idYY8yLw4pB1TwS8rgOuGGUfpUBpGIoXUZW1LQAsmqIBoZQan6J3eD3KVdS4mJKVHLdTZiilxj8NiAipqnVp60EpNa5pQESAq6uPD5o6dfxBKTWuaUBEwK5aF6DjD0qp8U0DIgIqNCCUUlFAAyICKmtcFE5IZoLeMlMpNY5pQERAZa2LxTr+oJQa5zQgxlhLZy9HmjtZqN1LSqlxTgNijFV5r6BePCUrsgVRSqlRaECMsQq9glopFSU0IMZYZY2LqdmRv1OUUkqNRgNijFXWuvQCOaVUVNCAGEPNHb3UnOhisXYvKaWigAbEGKrUC+SUUlFEA2IMVXkDYoEGhFIqCmhAjKGKmham5aSQmawD1Eqp8U8DYgxV1bayqDAr0sVQSqmQaECMkcb2HmpbdIBaKRU9NCDGiG+AWqfYUEpFCw2IMVJV4wuIjAiXRCmlQqMBMUYqal3MyEslPUkHqJVS0UEDYozoPaiVUtFGA2IMHG/r5qirWwNCKRVVNCDGQJVeQa2UikIaEGOgsqYVEb2CWikVXUIKCBE5S0Q+5n2dLCLp4S1WbKmsbWFmXhppiQmRLopSSoVs1IAQkf8DPAf8wruqEHg+jGWKORU1OkCtlIo+obQg7gAuBFoBjDH7gfxwFiqW1Ld2c7ytRwNCKRV1QgmIHmNMr29BRBIAE74ixZZK7wVyi/UmQUqpKBNKQLwuIt8BkkXkcuAPwJ/DW6zYUVnrwiYwf7JeQa2Uii6hBMQ9QANQCfwj8CLw3XAWKpZU1ro4Oz+NFKcOUCulostJj1oiYgMqjDELgf8cmyLFDmMMFTUuLp6dG+miKKXUKTtpC8IY4wF2isjUMSpPTKlv7aGxvUen+FZKRaVQupgmAbtE5FUR2eh7hLJzEblSRPaJyAERuTfI+5ki8mcR2Skiu0TkVu/6IhHZLCJ7vOu/emo/1vhQUdMCoDcJUkpFpVA6xu87nR2LiB14HLgcqAG2ishGY8zugM3uAHYbY64VkTxgn4g8BfQD/2SM2eG9KG+7iPx1yGfHPf8A9SQdoFZKRZ9RWxDGmNeBvUC697HHu2405wIHjDEHvafJPg1cN3T3QLqICJAGNAP9xpijxpgd3u9vA/YAU0L8mcaNyloXswvSSXbaI10UpZQ6ZaO2IETk08DDQCkgwM9F5G5jzHOjfHQKUB2wXAOsHLLNY8BGoA4rfFZ7xz0Cv38asAx4Z4Ty3QbcBlBQUEBpaeloPxIA7e3tIW97OowxbD/UyZK8hLB+z5kU7jqJNlofw2mdDBbr9RFKF9M/A+cYY44DeLuCXsGafuNkJMi6oRfY/R1QDlwKzAT+KiJvGmNavd+VBvwR+Jpv3bAdGvMk8CRAcXGxKSkpCeFHgtLSUkLd9nTUtXTRtuk1riieQ8n508L2PWdSuOsk2mh9DKd1Mlis10cog9Q2Xzh4NYX4uRqgKGC5EKulEOhWYL2xHAAOAXMBRMSBFQ5PGWPWh/B940pFjU7xrZSKbqG0IP5HRDYB67zLq4GXQvjcVmCWiEwHaoGbgM8O2eYIcBnwpogUAHOAg94xiV9hjXf8awjfNe5U1rZgtwnzdIBaKRWlRg0IY8zdIvJJ4CKsbqMnjTEbQvhcv4jcCWwC7MCvjTG7ROR27/tPAD8E1opIpXff9xhjGkXkIuBzQKWIlHt3+R1jzIun/iNGRmVtK7ML0kly6AC1Uio6hTJIPR140dfN470fxDRjzAejfdZ7QH9xyLonAl7XAVcE+dwWgo9hRAVjDJU1LVwxf2Kki6KUUqctlLGEPwCBZxa5vevUCGpbujjR2cdCncFVKRXFQgmIhMDpvr2vneErUvTzT/GtA9RKqSgWSkA0iMgnfAsich3QGL4iRb+KWhcJNmHORL0zq1IqeoVyFtPtwFMi8hjWuEA18PmwlirKVdW6mDNRB6iVUtEtlLOY3gfO8160Jt6pL9QIfFN8X7VIB6iVUtFt1C4mEfmqiGQAHcBPRWSHiAw780hZqpu7cHX1sVDHH5RSUS6UMYg13mkurgDysa5+fjCspYpilbW+AeqsyBZEKaU+pFACwnc9wlXAb4wxO4niaxTCraK2BafdxuyJaZEuilJKfSihBMR2EXkZKyA2ee/P4BnlM3HLN0CdmKAD1Eqp6BbKWUxfAJYCB40xnSKSg9XNpIbwDVBfu2RypIuilFIfWihnMXmAHQHLTVgzuqohDjd10tbdrzO4KqViQihdTCpEvgFqDQilVCzQgDiDKmtdOBNszC7QK6iVUtEvlOsgzvMOTPuW00Vk6K1DFdYcTPMmpuNM0NxVSkW/UI5k/wG0Byx3eNepAB6PoarWxSKdwVUpFSNCug7CGOO/l7R30DqUs5/iygdNHbT19OsFckqpmBFKQBwUka+IiMP7+CpwMNwFiza+AWqdYkMpFStCCYjbgQuw7itdA6wEbgtnoaJRZY2LxAQbswr0CmqlVGwI5TqI48BNY1CWqFZR62LepAwcdh2gVkrFhlDuSf0bwAxdb4xZE5YSRSGPx7Cr1sUNKwojXRSllDpjQhlsfiHgdRKwCqgLT3Gi08HGDjp63XqBnFIqpoTSxfTHwGURWQe8ErYSRaEq3xXUeoqrUiqGnE6H+Sxg6pkuSDSrqHGR5LBxdp4OUCulYkcoYxBtWGMQ4n0+BtwT5nJFlcraFuZPyiBBB6iVUjEklC4mnVjoJNwew666Vj5dXBTpoiil1BkV0hXRIjIBq2spybfOGPNGuAoVTQ42tNOpA9RKqRgUShfTF4GvAoVAOXAe8DZwaVhLFiUqdYBaKRWjQuk0/ypwDnDYGHMJsAxoCGupokhFjYtkh52ZOkCtlIoxoQREtzGmG0BEEo0xe4E54S1W9KisdbFwSgZ2m0S6KEopdUaFEhA1IpIFPA/8VUT+hF4oB0C/28PuuladoE8pFZNCOYtplfflD0RkM5AJ/E9YSxUl3m/ooKvPzWIdf1BKxaBTuq+DMeb1cBUkGlXUtAB6D2qlVGwK65VdInKliOwTkQMicm+Q9zNF5M8islNEdonIraF+djyoqnWR6rQzPVcHqJVSsSdsASEiduBx4OPAfOAzIjJ/yGZ3ALuNMUuAEuD/iYgzxM9GXEWtiwVTMnWAWikVk8LZgjgXOGCMOWiM6QWeBq4bso0B0kVEgDSgGegP8bMR5Rug1u4lpVSsCue9pacA1QHLvrvRBXoM2Ih1VlQ6sNoY4xGRUD4LgIjchvcOdwUFBZSWloZUuPb29pC3Daa6zUNPv4eE1jpKS4+f9n7Gkw9bJ7FG62M4rZPBYr0+whkQwfpdht546O+wrs6+FJiJdRrtmyF+1lppzJPAkwDFxcWmpKQkpMKVlpYS6rbBPLu1Gqhg9eXnMSNGLpL7sHUSa7Q+htM6GSzW6yOcXUw1QOAMdoUMv37iVmC9sRwADgFzQ/xsRFXWukhLTGBaTmqki6KUUmERzoDYCswSkeki4sS6r/XGIdscAS4DEJECrCu0D4b42Yiq8F5BbdMBaqVUjApbQBhj+oE7gU3AHuBZY8wuEbldRG73bvZD4AIRqQReBe4xxjSO9NlwlfVU9bk97DmqA9RKqdgWzjEIjDEvAi8OWfdEwOs64IpQPztevFffRm+/h0WFWZEuilJKhY3eAu00VNZYU3wv1haEUiqGaUCchspaF+lJCZyVkxLpoiilVNhoQJyGyloXi6ZkYl3fp5RSsUkD4hT19nvYe7RN7yCnlIp5GhCn6L36NnrdHj2DSSkV8zQgTlGFf4A6K7IFUUqpMNOAOEWVtS4ykx0UZSdHuihKKRVWGhCnqLK2RQeolVJxQQPiFPT0u9l3TAeolVLxQQPiFOw71kaf2+gAtVIqLmhAnALfALUGhFIqHmhAnIKqWhdZKQ4KJ+gAtVIq9mlAnIKKGr2CWikVPzQgQtTd5+a9+jYW6wC1UipOaECEaO+xNvo9OkCtlIofGhAhqqxpAdB7QCil4oYGRIgqalzkpDqZnJkU6aIopdSY0IAIUWWti4U6QK2UiiMaECHo7nOz/3i7DlArpeKKBkQIdh9txe0xLNQBaqVUHEmIdAGigf8e1NqCUDGor6+Pmpoauru7R902MzOTPXv2jEGpokM01UdSUhKFhYU4HI6QP6MBEYKKGhe5aYlMzNABahV7ampqSE9PZ9q0aaOOsbW1tZGenj5GJRv/oqU+jDE0NTVRU1PD9OnTQ/6cdjGFoKrWxaIpGTpArWJSd3c3OTk5+vsdw0SEnJyckFqJgTQgRtHZ28/+4216/YOKaRoOse90/o01IEax52grHgOLdYBaKRVnNCBG4Z/iWweolQqrDRs2ICLs3bs36PslJSVs27btpPsoKSlhzpw5LF26lHnz5vHkk0+e0TKuXbuWurq6M7rP8UwDYhSVNS7y0xMp0AFqpcJq3bp1XHTRRTz99NMfaj9PPfUU5eXlvPXWW9xzzz309vaeoRLGX0DoWUyjqKx16QR9Km7c9+dd7K5rHfF9t9uN3W4/pX3On5zB/712wUm3aW9v56233mLz5s184hOf4Ac/+AFdXV3ceuut7N69m3nz5tHV1eXf/ktf+hJbt26lq6uLG2+8kfvuuy/oPlNTU/3lXbduHf/yL/+CMYarr76ahx56aMT1brebL3zhC2zbtg0RYc2aNRQVFbFt2zZuvvlmkpOTefvtt0+pHqKRBsRJdPT0c6ChnasXT4p0UZSKac8//zxXXnkls2fPJjs7mx07dlBaWkpKSgoVFRVUVFSwfPly//YPPPAA2dnZuN1uLrvsMioqKli8eDEAN998M4mJiezfv59HH30Uu91OXV0d99xzD9u3b2fChAlcccUVPP/885x77rlB1xcVFVFbW0tVVRUALS0tZGVl8dhjj/HII49QXFwMWKe5xjINiJPYVdeKMXqBnIofo/2lH67z/tetW8fXvvY1AG666SbWrVvH/v37+cpXvgLA4sWL/QEA8Oyzz/Lkk0/S39/P0aNH2b17t//9p556iuLiYhoaGrjgggu48sorKS8vp6SkhLy8PMAKkTfeeAMRCbr+e9/7HgcPHuSuu+7i6quv5oorrjjjP3M00IA4icpaa4Bap9hQKnyampp47bXXqKqqQkRwu92ICMuWLQt6auahQ4d45JFH2Lp1KxMmTOCWW24Jen5/Xl4ey5cv55133sHpdAb9bmNM0PUTJkxg586dbNq0iccff5xnn32WX//61x/uB41COkh9EpU1LUzMSCI/XQeolQqX5557js9//vMcPnyYDz74gOrqaqZPn87y5ct56qmnAKiqqqKiogKA1tZWUlNTyczMpL6+npdeeinofjs7OykrK2PmzJmsXLmS119/ncbGRtxuN+vWreOjH/3oiOsbGxvxeDzccMMN/PCHP2THjh0ApKenx3y3UiBtQZxEZa1LT29VKszWrVvHvffeO2jdDTfcQFlZGV1dXSxevJilS5dy7rnnArBkyRKWLVvGggULmDFjBhdeeOGgz/oGkXt6erjllltYsWIFAD/+8Y+55JJLMMZw1VVXcd111424fufOndx66614PB7/NgC33HILt99+e9wMUmOMCdsDuBLYBxwA7g3y/t1AufdRBbiBbO97Xwd2edevA5JG+74VK1aYUG3evPmk77d29Zpp975gfvbKeyHvM9qNVifxJl7qY/fu3SFv29raGsaSRJ9oq49g/9bANjPCMTVsXUwiYgceBz4OzAc+IyLzh4TTw8aYpcaYpcC3gdeNMc0iMgX4ClBsjFkI2IGbwlXWYHwD1NqCUErFq3COQZwLHDDGHDTG9AJPA9edZPvPYLUUfBKAZBFJAFKAMb06pco7QK3XQCil4lU4xyCmANUByzXAymAbikgKVnfUnQDGmFoReQQ4AnQBLxtjXh7hs7cBtwEUFBRQWloaUuHa29tPuu0rO7vJThKqtsVBP6PXaHUSb+KlPjIzM0MeeHW73XE1SDuaaKuP7u7uU/qdDmdABJs6MPg5ZXAt8JYxphlARCZgtTamAy3AH0Tk740xvx+2Q2OeBJ4EKC4uNiUlJSEVrrS0lJNte/+2Us6ZmUZJSXFI+4sFo9VJvImX+tizZ0/I1zZEy/0Pxkq01UdSUhLLli0LeftwdjHVAEUBy4WM3E10E4O7lz4GHDLGNBhj+oD1wAVhKWUQrd19HGzs0O4lpVRcC2dAbAVmich0EXFihcDGoRuJSCbwUeBPAauPAOeJSIpYV8pcBozZff384w96DwilVBwLW0AYY/qxxhQ2YR3cnzXG7BKR20Xk9oBNV2GNMXQEfPYd4DlgB1DpLeeZnbf3JHSAWqmxV19fz2c/+1lmzJjBihUrOP/889mwYcNp7+8HP/gBjzzyCADf//73eeWVV05rP+Xl5bz44ov+5bVr15KXl+e/NuPGG2+ks7PztMs52vdt3LiRBx988Izt/1SE9UpqY8yLxpjZxpiZxpgHvOueMMY8EbDNWmPMsFNYjTH/1xgz1xiz0BjzOWNMTzjLGqiixsWUrGSyU4Nfnq+UOrOMMVx//fVcfPHFHDx4kO3bt/P0009TU1MzaLv+/v7T2v/999/Pxz72sdP67NADNsDq1aspLy/n3Xffxel08swzz5zWvkP5vk984hPDLiQcK3oldRCVtS6doE/Fp5fuhWOVI76d7O4H+ykeNiYugo+f/C/g1157DafTye23D3QunHXWWdx1112sXbuWv/zlL3R3d9PR0cHGjRu57rrrOHHiBH19ffzoRz/yXxX9wAMP8Nvf/paioiLy8vL8V1HfcsstXHPNNdx4441s376db3zjG7S3t5Obm8vatWuZNGkSJSUlrFy5ks2bN9PS0sKvfvUrVq5cyfe//326urrYsmUL3/72tweVu7+/n46ODiZMmADA4cOHWbNmDQ0NDeTl5fGb3/yGqVOnjrj+D3/4A/fddx92u53MzExeeeWVYd/X1dXFtm3beOyxx7jlllvIyMhg27ZtHDt2jJ/85CfceOONeDwe7rzzTl5//XWmT5+Ox+NhzZo13Hjjjaf2bzWEzsU0hKuzj8NNnTpBn1JjaNeuXYOm8x7q7bff5r/+67947bXXSEpKYsOGDezYsYPNmzfzT//0Txhj/K2OsrIy1q9fz9atW4ftp6+vj7vuuovnnnuO7du3s2bNGv75n//Z/35/fz/vvvsujz76KPfddx9Op5P777/f32JYvXo1AM888wxLly5lzpw5NDc3c+211wJw55138vnPf56Kigpuvvlm/2y0I62///772bRpEzt37mTjxo0jfl+go0ePsmXLFl544QV/y2L9+vV88MEHVFZW8stf/vKMTQOiLYghquqs8QdtQai4NMpf+l1jdFrnHXfcwZYtW3A6ndxxxx1cfvnlZGdnA1Z31He+8x3eeOMNbDYbtbW11NfX8+abb7Jq1SpSUlIAq2tmqH379lFVVcXll18OWNcxTJo0cL+XT37ykwCsWLGCDz74YMTyrV69mscee4zW1lbuvfdeHn74Ye69917efvtt1q9fD8DnPvc5vvWtbwGMuP7CCy/klltu4dOf/rT/u0dz/fXXY7PZmD9/PvX19QBs2bKFT33qU9hsNiZOnMgll1wS0r5Goy2IISp1gFqpMbdgwQL/jKkAjz/+OK+++ioNDQ0ApKam+t976qmnaGhoYPv27ZSXl1NQUOCf7jvY9OCBjDEsWLCA8vJyysvLqays5OWXB67BTUxMBMBut4c03iEiXHvttbzxxhsjvn+y9U888QQ/+tGPqK6uZunSpTQ1NY36nb4y+n6ewOczTQNiiMoaF0XZyWSl6AC1UmPl0ksvpbu7m//4j//wrxvpzCCXy0V+fj4Oh4PNmzdz+PBhAC6++GI2bNhAV1cXbW1t/PnPfx722Tlz5tDQ0ODvgunr62PXrl0nLdtoU3xv2bKFmTNnAnDBBRf476n91FNPcdFFF510/fvvv8/KlSu5//77yc3Npbq6+rSmFL/ooov44x//iMfjob6+/ozNAKBdTENU1LaweEpWpIuhVFwREZ5//nm+/vWv85Of/IS8vDxSU1N56KGHBt2LGqzpvK+99lqKi4tZunQpc+fOBWD58uWsXr2apUuXctZZZ/GRj3xk2Pc4nU6ee+45vvKVr+Byuejv7+drX/saCxaMfCe9Sy65hAcffJClS5f6B6mfeeYZtmzZQn9/P1OnTmXt2rUA/Nu//Rtr1qzh4Ycf9g9Gn2z93Xffzf79+zHGcNlll7FkyRKmTp067PtGc8MNN/Dqq6+ycOFCZs+ezcqVK8nMPAO9ICNN8xqNjw873feJjh5z1j0vmH/ffCDk/cSSeJneOlTxUh863ffpG0/10dbWZowxprGx0cyYMcMcPXp02DanOt23tiAC+MYfdIBaKRVtrrnmGlpaWujt7eV73/seEydO/ND71IAI4L8H9WQNCKVUdAnHzMM6SB2gssbFWTkpZKY4Il0UpZSKOA2IABU1Lj29VSmlvDQgvJo7eqlt6dLxB6WU8tKA8PKPP2gLQimlAA0Iv8qaFkADQqmxVl1dzfTp02lubgbgxIkTTJ8+ncOHD7N//36uueYaZs6cyYoVK7jkkkv8Vy0HTru9YMGCsE+7HY80ILwqa11Mz00lI0kHqJUaS0VFRXzpS1/yTzx37733ctttt1FQUMDVV1/Nbbfdxvvvv8/27dv5+c9/zsGDB/2f9U1qt2vXrrBPux2P9DRXr8oaF8XTsiNdDKUi6qF3H2Jv894R33e73djt9lPa59zsudxz7j0n3ebrX/86K1as4NFHH2XLli38/Oc/53e/+x3nn3/+oEn3Fi5cyMKFC4d9fiym3Q42s2qs0xYE0NjeQ52rWweolYoQh8PBww8/zNe//nUeffRRnE7nqFOAw8C021OmTBnzabfjgbYg0AFqpXxG+0u/LYzTfb/00ktMmjRp0HTcgVatWsX+/fuZPXu2f+ps37TbxhjuuOOOMZ12Ox5oCwKre0kEFkzOiHRRlIpL5eXl/PWvf+Vvf/sbP/3pTzl69OiwKcA3bNjA2rVr/YPZgSIx7XY80IDAakHMyE0lXQeolRpzxhi+9KUv8eijjzJ16lTuvvtuvvnNb/LZz36Wt956i40bN/q3PdlZSuNh2u1YowGB1YLQK6iVioz//M//ZOrUqf5upS9/+cvs3buXd999lxdeeIEnnniCGTNmcP755/OjH/2I7373u/7P+sYgFi9eTFlZGd/73vcAa3rt3/zmNyxevJjf/e53/OxnPzvp+rvvvptFixaxcOFCLr74YpYsWcIll1zC7t27Wbp06Rk9OyqaiAnTnYgiobi42Gzbti2kbUtLSykpKaG338N3NlRy0dm5XL9sSphLOL756kRZ4qU+9uzZw7x580LaNpxjENEo2uoj2L+1iGw3xhQH2z7uB6mdCTYe+dSSSBdDKaXGHe1iUkopFZQGhFIqbDe9V+PH6fwba0AoFeeSkpJoamrSkIhhxhiamppISko6pc/F/RiEUvGusLCQmpoaGhoaRt22u7v7lA8ysSya6iMpKYnCwsJT+owGhFJxzuFwMH369JC2LS0tZdmyZWEuUfSI9frQLiallFJBaUAopZQKSgNCKaVUUDF1JbWINACHQ9w8F2gMY3GikdbJYFofw2mdDBYL9XGWMSYv2BsxFRCnQkS2jXR5ebzSOhlM62M4rZPBYr0+tItJKaVUUBoQSimlgorngHgy0gUYh7ROBtP6GE7rZLCYro+4HYNQSil1cvHcglBKKXUSGhBKKaWCisuAEJErRWSfiBwQkXsjXZ6xJiJFIrJZRPaIyC4R+ap3fbaI/FVE9nufJ0S6rGNJROwiUiYiL3iX470+skTkORHZ6/1dOT+e60REvu79/1IlIutEJCnW6yPuAkJE7MDjwMeB+cBnRGR+ZEs15vqBfzLGzAPOA+7w1sG9wKvGmFnAq97lePJVYE/AcrzXx8+A/zHGzAWWYNVNXNaJiEwBvgIUG2MWAnbgJmK8PuIuIIBzgQPGmIPGmF7gaeC6CJdpTBljjhpjdnhft2H9x5+CVQ//5d3sv4DrI1LACBCRQuBq4JcBq+O5PjKAi4FfARhjeo0xLcRxnWDNfp0sIglAClBHjNdHPAbEFKA6YLnGuy4uicg0YBnwDlBgjDkKVogA+REs2lh7FPgW4AlYF8/1MQNoAH7j7Xb7pYikEqd1YoypBR4BjgBHAZcx5mVivD7iMSAkyLq4PNdXRNKAPwJfM8a0Rro8kSIi1wDHjTHbI12WcSQBWA78hzFmGdBBjHWfnArv2MJ1wHRgMpAqIn8f2VKFXzwGRA1QFLBciNVUjCsi4sAKh6eMMeu9q+tFZJL3/UnA8UiVb4xdCHxCRD7A6nK8VER+T/zWB1j/T2qMMe94l5/DCox4rZOPAYeMMQ3GmD5gPXABMV4f8RgQW4FZIjJdRJxYA00bI1ymMSUigtW3vMcY868Bb20E/sH7+h+AP4112SLBGPNtY0yhMWYa1u/Da8aYvydO6wPAGHMMqBaROd5VlwG7id86OQKcJyIp3v8/l2GN3cV0fcTlldQichVWn7Md+LUx5oHIlmhsichFwJtAJQN97t/BGod4FpiK9R/iU8aY5ogUMkJEpAT4pjHmGhHJIY7rQ0SWYg3aO4GDwK1Yf1TGZZ2IyH3AaqyzAMuALwJpxHB9xGVAKKWUGl08djEppZQKgQaEUkqpoDQglFJKBaUBoZRSKigNCKWUUkFpQCh1GrwznX450uVQKpw0IJQ6PVnAsIDwzhasVEzQgFDq9DwIzBSRchHZ6r2/xn8Dld77SjzsXV8hIv/o+5CI3B2w/j7vulQR+YuI7PTea2B1pH4opQIlRLoASkWpe4GFxpil3quv/+JdPiQit2HN9nmOiCQCb4nIy8As7+NcrEkjN4rIxUAeUGeMuRpARDLH/sdRajgNCKXOjHeNMYe8r68AFovIjd7lTKxguML7KPOuT/OufxN4REQeAl4wxrw5dsVWamQaEEqdGR0BrwW4yxizKXADEfk74MfGmF8M/bCIrACuAn4sIi8bY+4Pa2mVCoGOQSh1etqA9BHe2wR8yTulOiIy23uznU3AGu99OBCRKSKSLyKTgU5jzO+xbkqzPPzFV2p02oJQ6jQYY5pE5C0RqQK6gPqAt38JTAN2eKeGbgCuN8a8LCLzgLet1bQDfw+cDTwsIh6gD/jS2P0kSo1MZ3NVSikVlHYxKaWUCkoDQimlVFAaEEoppYLSgFBKKRWUBoRSSqmgNCCUUkoFpQGhlFIqqP8PaBacjySzi3sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(trees, ada_scoring.mean(axis=1), label='AdaBoost')\n",
    "plt.plot(trees, gbc_scoring.mean(axis=1), label='GradientBoosting')\n",
    "plt.plot(trees, xgb_scoring.mean(axis=1), label='XGBoost')\n",
    "plt.grid(True)\n",
    "plt.xlabel('trees')\n",
    "plt.ylabel('auc score')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3968fee",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Видим ожидаемую картину: при одном дереве качество работы алгоритма было ниже, чем с увеличением количества деревьев, однако все модели показывают наиболее высокое качество примерно у отметки в 20 базовых деревьев. Вообще, в бустинге увеличение числа деревьев не всегда приводит к улучшению качества решения на тестовых данных. Число деревьев, при котором качество алгоритма максимально, зависит от темпа обучения: чем меньше темп, тем больше деревьев обычно нужно (отметим, что зависимость нелинейная).\n",
    "\n",
    "Также, как видно по графику, алгоритм XGBoost работает не только быстрее, но и несколько лучше. Это достигается за счет того, что у него больше преднастроенных гиперпараметров и он лучше оптимизирован."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adccaa3f",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bea13a",
   "metadata": {},
   "source": [
    "Теперь поговорим о стекинге - другом популярном способе ансамблирования алгоритмов. Он принципиально отличается от бустинга двумя положениями. Первое, в стекинге обычно используются разнородные базовые алгоритмы (например, kNN, метод опорных векторов и дерево решений), тогда как в бустинге обычно используют ансамбли однородных алгоритмов (обычно применяются деревья решений). Второе, стекинг объединяет базовые алгоритмы, используя мета-алгоритм, который самостоятельно обучается на предоставленных базовыми моделями данных. Бустинг в свою очередь объединяет их, следуя детерминированному алгоритму."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a252e1",
   "metadata": {},
   "source": [
    "Идея стекинга лежит на поверхности. Известно, что, если обучить несколько разных алгоритмов, то в задаче регрессии их среднее, а в задаче классификации — голосование по большинству, часто превосходят по качеству все эти алгоритмы по отдельности. Возникает вопрос: почему, собственно, нужно использовать для ансамблирования такие операции как усреднение или голосование? Можно же доверить ансамблироование очередному алгоритму (т.н. мета-алгоритму) машинного обучения, чтобы он сам решил, как ему действовать с полученными ответами базовых алгоритмов.\n",
    "\n",
    "Чтобы понять, как работает классический стекинг, сначала разберем его простейшую реализацию - **блендинг (blending)**. Обучающую выборку делят на две части. \n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/blending_1.png)\n",
    "\n",
    "На первой обучают базовые алгоритмы. Затем получают их ответы на второй части и на тестовой выборке. \n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/blending_2.png)\n",
    "\n",
    "Понятно, что  ответ каждого алгоритма можно рассматривать как новый признак (т.н. метапризнак). На метапризнаках второй части обучения настраивают метаалгоритм. Затем запускают его на метапризнаках теста и получают ответ.\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/blending_3.png)\n",
    "\n",
    "В такой реализации самый большой недостаток - деление обучающей выборки. Получается, что ни базовые алгоритмы, ни метаалгоритм не используют всего объёма обучения, а значит, мы можем пропустить важные данные.\n",
    "\n",
    "Один из способов борьбы за использование всей обучающей выборки - реализация классического **стекинга (stacking)**. Понятно, что обучить базовые алгоритмы на всей обучающей выборке и потом для той же выборки построить метапризнаки нельзя: будет очевидное переобучение. Поэтому выборку разбивают на части (т.н. фолды, как в кросс-валидации).\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/meta_1.png)\n",
    "\n",
    "Затем последовательно для каждого обучают базовые алгоритмы на всех фолдах, кроме одного, а на оставшемся получают ответы базовых алгоритмов и трактуют их как значения соответствующих метапризнаков на этом фолде.\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/meta_2.png)\n",
    "\n",
    "Для получения метапризнаков объектов тестовой выборки базовые алгоритмы обучают на всей тренировочной выборке и берут их ответы на тестовой.\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/meta_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c703e9",
   "metadata": {},
   "source": [
    "Для примера, если взять M базовых алгоритмов и обучить их на N объектах, то окончательная матрица метапризнаков для обучения мета-алгоритма будет выглядеть так:\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/meta_mtrx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd54c0",
   "metadata": {},
   "source": [
    "Отметим, что стекинг не всегда существенно повышает качество лучшего из базовых алгоритмов, однако если этот алгоритм убрать из базовых, то и качество стекинга не сильно падает.\n",
    "\n",
    "Также возможно использовать стекинг с несколькими слоями, т.н. многоуровневый стекинг, т.е. ввести понятие мета-мета признака и мета-мета алгоритма и далее при желании расширить еще на несколько слоев. Такой метод часто применяется в соревнованиях по машинному обучению, где борьба идет за десятитысячные доли к точности модели, однако саму модель это сделает неинтерпретируемой, что плохо для бизнес-задач."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cdf23",
   "metadata": {},
   "source": [
    "Вообще, в sklearn нет реализации стекинга, но существуют такие небазовые пакеты python как mlxtend или vecstack, в которых присутствует этот метод, которым можно воспользоваться \"из коробки\".\n",
    "\n",
    "Мы же на примере базовой реализации блендинга покажем, как работает этот метод. В качестве базовых алгоритмов возьмем kNN, LogisticRegression, DesisionTreeClassifier и SupportVectorClassification, а в качестве мета-алгоритма будем использовать XGBoost.\n",
    "\n",
    "Будем проверять работу стекинга на том же преобразованном датасете Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c2c5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b361e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic.csv')\n",
    "targets = titanic.Survived\n",
    "data = titanic.drop(columns='Survived')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, \n",
    "                                                    targets,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311bced",
   "metadata": {},
   "source": [
    "Так как нам нужно и обучить базовые алгоритмы на тренировочном сете, и сделать на этих же данных предсказания для обучения мета-алгоритма, разделим тренировочные данные еще на два датасета: train и valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc093d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, train_true, valid_true = train_test_split(x_train, \n",
    "                                                        y_train,\n",
    "                                                        train_size=0.5,\n",
    "                                                        random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e65e46",
   "metadata": {},
   "source": [
    "Обучим базовые алгоритмы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b8bd093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/roman/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model = knn.fit(train, train_true)\n",
    "\n",
    "lr = LogisticRegression(random_state=17)\n",
    "lr_model = lr.fit(train, train_true)\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_leaf_nodes=4, random_state=17)\n",
    "dtc_model = lr.fit(train, train_true)\n",
    "\n",
    "svc = SVC(random_state=17)\n",
    "svc_model = svc.fit(train, train_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca760be6",
   "metadata": {},
   "source": [
    "Теперь получим предсказания моделей для второй части тренировочных данных - valid, заполним получившимися метапризнаками матрицу для обучения мета-алгоритма и обучим его.\n",
    "\n",
    "Заодно получим для каждого базового алгоритма метрику AUC для тестовых данных, которая покажет качество работы каждого алгоритма в отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4933f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 auc: 0.7080368906455863\n",
      "1 auc: 0.8094861660079051\n",
      "2 auc: 0.8094861660079051\n",
      "3 auc: 0.6538866930171279\n",
      "[18:00:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "models = [knn_model, lr_model, dtc_model, svc_model]\n",
    "meta_mtrx = np.empty((valid.shape[0], len(models))) # (кол-во объектов, 4 алгоритма)\n",
    "\n",
    "for n, model in enumerate(models):\n",
    "    meta_mtrx[:, n] = model.predict(valid)\n",
    "    predicted = model.predict(x_test)\n",
    "    print(f'{n} auc: {roc_auc_score(y_test, predicted)}')\n",
    "    \n",
    "meta = XGBClassifier(n_estimators=40)\n",
    "meta_model = meta.fit(meta_mtrx, valid_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068471b",
   "metadata": {},
   "source": [
    "Получим метапризнаки базовых алгоритмов для тестовых данных, чтобы мета-алгоритм мог по ним сделать предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b40adb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking AUC: 0.8094861660079051\n"
     ]
    }
   ],
   "source": [
    "meta_mtrx_test = np.empty((x_test.shape[0], len(models))) \n",
    "\n",
    "for n, model in enumerate(models):\n",
    "    meta_mtrx_test[:, n] = model.predict(x_test)\n",
    "    \n",
    "meta_predict = meta.predict(meta_mtrx_test)\n",
    "print(f'Stacking AUC: {roc_auc_score(y_test, meta_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec48e92",
   "metadata": {},
   "source": [
    "Как мы видим, в этом случае финальный скор AUC не превышает результат лучших базовых алгоритмов. Попробуем убрать базовые алгоритмы с лучшими результатами и посмотреть, что изменится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "739d2953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 auc: 0.7080368906455863\n",
      "1 auc: 0.6538866930171279\n",
      "[18:01:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Stacking AUC: 0.6538866930171279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "models = [knn_model, svc_model]\n",
    "meta_mtrx = np.empty((valid.shape[0], len(models))) # (кол-во объектов, 4 алгоритма)\n",
    "\n",
    "for n, model in enumerate(models):\n",
    "    meta_mtrx[:, n] = model.predict(valid)\n",
    "    predicted = model.predict(x_test)\n",
    "    print(f'{n} auc: {roc_auc_score(y_test, predicted)}')\n",
    "\n",
    "meta_model = meta.fit(meta_mtrx, valid_true)\n",
    "\n",
    "meta_mtrx_test = np.empty((x_test.shape[0], len(models))) \n",
    "\n",
    "for n, model in enumerate(models):\n",
    "    meta_mtrx_test[:, n] = model.predict(x_test)\n",
    "    \n",
    "meta_predict = meta.predict(meta_mtrx_test)\n",
    "print(f'Stacking AUC: {roc_auc_score(y_test, meta_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45b4cb",
   "metadata": {},
   "source": [
    "Здесь же видно, что стекинг двух не самых лучших базовых алгоритмов дает результат выше, чем у каждого из них по отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7484a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
