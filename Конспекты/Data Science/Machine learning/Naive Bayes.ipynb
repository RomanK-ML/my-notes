{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2de1ab6",
   "metadata": {},
   "source": [
    "# Наивный байесовский классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef5183",
   "metadata": {},
   "source": [
    "Наивный байесовский классификатор - семейство алгоритмов классификации, которые принимают допущение о том, что каждый параметр классифицируемых данных не зависит от других параметров объектов, т.е. ни один из параметров не оказывает влияние на другой.\n",
    "Согласитесь, что достаточно наивно было бы предполагать, что, допустим, рост и вес человека - совершенно независимые параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e858b7b",
   "metadata": {},
   "source": [
    "Вероятность того, что объект принадлежит какому-либо классу при данных параметрах обозначается как: \n",
    "\n",
    "$$\n",
    "P(Class|Long, Sweet, Yellow)\n",
    "$$\n",
    "\n",
    "Чтобы вычислить вероятность в случае дискретных (конечных) данных, мы делим количество соответствующих признаку объектов на общее число объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfe9f6a",
   "metadata": {},
   "source": [
    "Данный метод основан на теореме английского математика-статистика Томаса Байеса. По сути, она позволяет предсказать класс на основании набора параметров, используя вероятность. Общая формула Байеса для класса с одним признаком выглядит так:\n",
    "\n",
    "$$\n",
    "P(Class A|Feature 1) = \\frac{P(Feature 1|Class A)\\cdot P(Class A)}{P(Feature 1)}\n",
    "$$\n",
    "\n",
    "$P(Class A|Feature 1)$ - вероятность того, что объект является классом $A$ при том, что его признак соответствует $Feature 1$.\n",
    "\n",
    "Упрощенное уравнение для классификации при двух признаках выглядит так:\n",
    "\n",
    "$$\n",
    "P(Class A|Feature 1, Feature 2) = \\frac{P(Feature 1|Class A)\\cdot P(Feature 2|Class A)\\cdot P(Class A)}{P(Feature 1)\\cdot P(Feature 2)}\n",
    "$$\n",
    "\n",
    "И далее для большего количества признаков формула меняется соответствующим образом.\n",
    "\n",
    "Напомним, что вероятность - число, которое принимает значения от 0 до 1, при этом 0 - полное несоответствие класса признакам, а 1 - однозначно определенный класс. Соответственно, чем ближе значение вероятности определенного класса к 1, тем больше шанс того, что объект принадлежит именно этому классу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f73170",
   "metadata": {},
   "source": [
    "Знаменатель можно проигнорировать, так как он будет одинаков для всех вычислений и никакой важной информации не даст.\n",
    "Тогда получится следующее уравнение:\n",
    "\n",
    "$$\n",
    "P(Class A|Feature 1, Feature 2) = P(Feature 1|Class A)\\cdot P(Feature 2|Class A)\\cdot P(Class A)\n",
    "$$\n",
    "\n",
    "То есть для каждого возможного класса вычисляем только произведение вероятностей того, что каждый признак соответствует классу, и вероятности того, что объект принадлежит этому классу. Соответственно, наибольшее значение этого произведения, рассчитанного с признаками конкретного объекта, для какого-то из классов будет указывать на принадлежность объекта к этому классу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f12b73",
   "metadata": {},
   "source": [
    "Но что делать, если у нас не частотная таблица, как в примере выше, а непрерывные данные? Например, мы не можем вычислять, сколько человек с конкретным ростом 1,81м, 1,67м и т.д. присутствует в выборке - нам это попросту ничего не даст, а лишь добавит громоздких вычислений. Поэтому обычно при непрерывных значениях параметров используется гауссовский наивный Байес, в котором сделано предположение о том, что значения параметров взяты из нормального распределения.\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS_Block2_M5_final/GNB.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f0cc0e",
   "metadata": {},
   "source": [
    "На графике - плотность вероятности нормального распределения. По сути, где больше площадь под графиком, там и наиболее вероятные значения. Поскольку способ представления значений в наборе данных изменяется, то и формула условной вероятности изменяется на \n",
    "\n",
    "$$\n",
    "p(x_i|y) = \\frac{1}{\\sqrt{2\\pi \\sigma^2_y}}exp(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y})\n",
    "$$\n",
    "\n",
    "Здесь $\\sigma^2$ - дисперсия (разброс) данных, а $\\mu$ - математическое ожидание (среднее значение). При этом $y$ - предполагаемый класс, а $x_i$ - значение признака у того объекта, который нужно классифицировать.\n",
    "\n",
    "По большому счету в нашей начальной формуле для вычисления вероятности того, что объект с данными признаками относится к конкретному классу, мы просто заменяем формулу вычисления вероятности как отношения количества соответствующих признаку объектов к общему числу объектов на данную, а дальше проводим идентичные вычисления."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a555abe",
   "metadata": {},
   "source": [
    "Помимо гауссовского существуют еще два типа моделей на основе наивного байесовского классификатора: полиномиальная и с распределением Бернулли. *Полиномиальная* в основном используется для задачи классификации документов, т.е. определяет, к каким категориям относится текст: спорт, политика, техника и т.д. Используемые признаки являются частотой слов, присутствующих в документе. *Классификатор на основе распределения Бернулли* похож на полиномиальный метод, но признаками являются булевы переменные, т.е. они принимают только значения \"yes\" и \"no\" - например, встречается слово в тексте или нет. Используется в основном для классификации небольших текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19c3864",
   "metadata": {},
   "source": [
    "# Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169bebb8",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73abe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65edd8c6",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5630e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = load_iris() # возвращает объект с несколькими полями\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_dataset.data[:, 2:4], \n",
    "                                                    iris_dataset['target'],\n",
    "                                                    random_state=0) # random_state - для воспроизводимости"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb6ac9",
   "metadata": {},
   "source": [
    "# Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8cf1b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb_model = nb.fit(x_train, y_train)\n",
    "nb_predictions = nb.predict(x_test)\n",
    "nb_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ce6247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "accuracy = nb.score(x_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bce84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
